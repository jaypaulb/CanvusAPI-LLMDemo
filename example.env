# ======================
# API Keys & Authentication
# ======================
# OpenAI API key for AI integration (required for AI features)
OPENAI_API_KEY=your-openai-api-key

# Google Vision API key for image analysis (optional)
GOOGLE_VISION_API_KEY=your-google-vision-api-key

# Canvus API key for authentication with Canvus server (required)
CANVUS_API_KEY=your-canvus-api-key

# WebUI authentication key for securing the web interface
WEBUI_PWD=your-password

# ======================
# Server Configuration
# ======================
# Canvus server URL - The base URL for the Canvus instance
CANVUS_SERVER=https://your.canvus.server/

# Canvas configuration - Name and ID of the canvas to control
CANVAS_NAME=your canvas name
CANVAS_ID=your-canvas-id

# Local server settings
PORT=3000

# SSL/TLS Configuration
# Allow self-signed certificates (default: false)
# WARNING: Setting this to true disables SSL certificate validation
ALLOW_SELF_SIGNED_CERTS=true

# ======================
# LLM API Configuration
# ======================
# Base LLM API URL - Used as default if specific endpoints aren't set
# Examples:
# - OpenAI API: https://api.openai.com/v1
# - Local LLM: http://localhost:1234/v1
# - Ollama: http://localhost:11434/v1
BASE_LLM_URL=http://127.0.0.1:1234/v1

# Optional: Override URL for text generation
# If not set, BASE_LLM_URL will be used
TEXT_LLM_URL=

# Optional: Override URL for image generation
# If not set, BASE_LLM_URL will be used
# For OpenAI DALL-E: https://api.openai.com/v1
# For local Stable Diffusion: http://localhost:7860/v1
IMAGE_LLM_URL=

# ======================
# Model Selection
# ======================
# Model to use for note processing (default: gpt-3.5-turbo)
# Examples for local LLMs:
# - LLaMA 2: llama2
# - Mistral: mistral
# - CodeLlama: codellama
# - Local model name as configured in your LLM server
OPENAI_NOTE_MODEL=gpt-4

# Model to use for canvas analysis (default: gpt-4)
# For local LLMs, use the same model name as configured in your server
OPENAI_CANVAS_MODEL=gpt-4

# Model to use for PDF analysis (default: gpt-4)
# For local LLMs, use the same model name as configured in your server
OPENAI_PDF_MODEL=gpt-4

# ======================
# Token Limits
# ======================
# Token limits for different operations (defaults shown)
# Note: Local LLMs may have different token limits, adjust accordingly
OPENAI_PDF_PRECIS_TOKENS=4000        # Longer for document analysis
OPENAI_CANVAS_PRECIS_TOKENS=4000      # Medium for canvas overview
OPENAI_NOTE_RESPONSE_TOKENS=2000      # Standard for note responses
OPENAI_IMAGE_ANALYSIS_TOKENS=1000     # Brief for image descriptions
OPENAI_ERROR_RESPONSE_TOKENS=500      # Short for error messages
OPENAI_PDF_CHUNK_SIZE_TOKENS=2000     # Size of individual PDF chunks
OPENAI_PDF_MAX_CHUNKS_TOKENS=10000    # Maximum number of PDF chunks to process
OPENAI_PDF_SUMMARY_RATIO=0.25         # Target ratio of summary to original length

# ======================
# Processing Configuration
# ======================
# Maximum concurrent processes (default: 5)
MAX_CONCURRENT=5

# Processing timeout in seconds (default: 300)
PROCESSING_TIMEOUT=300

# Maximum file size in bytes (default: 52428800 - 50MB)
MAX_FILE_SIZE=52428800

# Downloads directory (default: ./downloads)
DOWNLOADS_DIR=./downloads

# Timeouts and retries
MAX_RETRIES=3
RETRY_DELAY=1s
AI_TIMEOUT=60s
